{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3pHkBAJPoAp"
      },
      "source": [
        "# Portfolio Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_d3otlJPoA1"
      },
      "source": [
        "“Modern Portfolio Theory (MPT), a hypothesis put forth by Harry Markowitz in his paper “Portfolio Selection,” (published in 1952 by the Journal of Finance) is an investment theory based on the idea that risk-averse investors can construct portfolios to optimize or maximize expected return based on a given level of market risk, emphasizing that risk is an inherent part of higher reward. It is one of the most important and influential economic theories dealing with finance and investment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-hbvg6SPoBC"
      },
      "source": [
        "## Monte Carlo Simulation for Optimization Search\n",
        "\n",
        "\n",
        "We could randomly try to find the optimal portfolio balance using Monte Carlo simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "56N4a0t3PoBD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "yLZJI1buPoBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "05b53edc-683e-462d-8a54-007abbcff780"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'AAPL_CLOSE'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-da0671966f84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download and get Daily Returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL_CLOSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcisco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CISCO_CLOSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mibm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IBM_CLOSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mamzn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AMZN_CLOSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_CLOSE'"
          ]
        }
      ],
      "source": [
        "# Download and get Daily Returns\n",
        "aapl = pd.read_csv('AAPL_CLOSE',index_col='Date',parse_dates=True)\n",
        "cisco = pd.read_csv('CISCO_CLOSE',index_col='Date',parse_dates=True)\n",
        "ibm = pd.read_csv('IBM_CLOSE',index_col='Date',parse_dates=True)\n",
        "amzn = pd.read_csv('AMZN_CLOSE',index_col='Date',parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FVB5zJF8PoBH"
      },
      "outputs": [],
      "source": [
        "stocks = pd.concat([aapl,cisco,ibm,amzn],axis=1)\n",
        "stocks.columns = ['aapl','cisco','ibm','amzn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSIK4dxCPoBH"
      },
      "outputs": [],
      "source": [
        "stocks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lopVgPb6PoBI"
      },
      "outputs": [],
      "source": [
        "mean_daily_ret = stocks.pct_change(1).mean()\n",
        "mean_daily_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_3g-t5GPoBI"
      },
      "outputs": [],
      "source": [
        "stocks.pct_change(1).corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQSHgkpAPoBJ"
      },
      "source": [
        "# Simulating Thousands of Possible Allocations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYCw2takPoBJ"
      },
      "outputs": [],
      "source": [
        "stocks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMMV3vv_PoBJ"
      },
      "outputs": [],
      "source": [
        "stock_normed = stocks/stocks.iloc[0]\n",
        "stock_normed.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyMPqkTlPoBJ"
      },
      "outputs": [],
      "source": [
        "stock_daily_ret = stocks.pct_change(1)\n",
        "stock_daily_ret.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6xdqubVPoBJ"
      },
      "source": [
        "## Log Returns vs Arithmetic Returns\n",
        "\n",
        "We will now switch over to using log returns instead of arithmetic returns, for many of our use cases they are almost the same,but most technical analyses require detrending/normalizing the time series and using log returns is a nice way to do that.\n",
        "Log returns are convenient to work with in many of the algorithms we will encounter.\n",
        "\n",
        "For a full analysis of why we use log returns, check [this great article](https://quantivity.wordpress.com/2011/02/21/why-log-returns/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URDWWbRDPoBK"
      },
      "outputs": [],
      "source": [
        "log_ret = np.log(stocks/stocks.shift(1))\n",
        "log_ret.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngoP_0YRPoBL"
      },
      "outputs": [],
      "source": [
        "log_ret.hist(bins=100,figsize=(12,6));\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7TRr_ZdPoBL"
      },
      "outputs": [],
      "source": [
        "log_ret.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3hXdfN2PoBL"
      },
      "outputs": [],
      "source": [
        "log_ret.mean() * 252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX1GVAyePoBL"
      },
      "outputs": [],
      "source": [
        "# Compute pairwise covariance of columns\n",
        "log_ret.cov()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7TDf1owPoBL"
      },
      "outputs": [],
      "source": [
        "log_ret.cov()*252 # multiply by days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yes2O_G8PoBM"
      },
      "source": [
        "## Single Run for Some Random Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d93Cdw9dPoBM"
      },
      "outputs": [],
      "source": [
        "# Set seed (optional)\n",
        "np.random.seed(101)\n",
        "\n",
        "# Stock Columns\n",
        "print('Stocks')\n",
        "print(stocks.columns)\n",
        "print('\\n')\n",
        "\n",
        "# Create Random Weights\n",
        "print('Creating Random Weights')\n",
        "weights = np.array(np.random.random(4))\n",
        "print(weights)\n",
        "print('\\n')\n",
        "\n",
        "# Rebalance Weights\n",
        "print('Rebalance to sum to 1.0')\n",
        "weights = weights / np.sum(weights)\n",
        "print(weights)\n",
        "print('\\n')\n",
        "\n",
        "# Expected Return\n",
        "print('Expected Portfolio Return')\n",
        "exp_ret = np.sum(log_ret.mean() * weights) *252\n",
        "print(exp_ret)\n",
        "print('\\n')\n",
        "\n",
        "# Expected Variance\n",
        "print('Expected Volatility')\n",
        "exp_vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
        "print(exp_vol)\n",
        "print('\\n')\n",
        "\n",
        "# Sharpe Ratio\n",
        "SR = exp_ret/exp_vol\n",
        "print('Sharpe Ratio')\n",
        "print(SR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH7NCtmrPoBM"
      },
      "source": [
        "Great! Now we can just run this many times over!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UTiSBYoDPoBM"
      },
      "outputs": [],
      "source": [
        "num_ports = 15000\n",
        "\n",
        "all_weights = np.zeros((num_ports,len(stocks.columns)))\n",
        "ret_arr = np.zeros(num_ports)\n",
        "vol_arr = np.zeros(num_ports)\n",
        "sharpe_arr = np.zeros(num_ports)\n",
        "\n",
        "for ind in range(num_ports):\n",
        "\n",
        "    # Create Random Weights\n",
        "    weights = np.array(np.random.random(4))\n",
        "\n",
        "    # Rebalance Weights\n",
        "    weights = weights / np.sum(weights)\n",
        "\n",
        "    # Save Weights\n",
        "    all_weights[ind,:] = weights\n",
        "\n",
        "    # Expected Return\n",
        "    ret_arr[ind] = np.sum((log_ret.mean() * weights) *252)\n",
        "\n",
        "    # Expected Variance\n",
        "    vol_arr[ind] = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
        "\n",
        "    # Sharpe Ratio\n",
        "    sharpe_arr[ind] = ret_arr[ind]/vol_arr[ind]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuxDrsbJPoBM"
      },
      "outputs": [],
      "source": [
        "sharpe_arr.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UkG8-HdPoBN"
      },
      "outputs": [],
      "source": [
        "sharpe_arr.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH49WTCOPoBN"
      },
      "outputs": [],
      "source": [
        "all_weights[1419,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DCL_NLr0PoBN"
      },
      "outputs": [],
      "source": [
        "max_sr_ret = ret_arr[1419]\n",
        "max_sr_vol = vol_arr[1419]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnpT9eG4PoBN"
      },
      "source": [
        "## Plotting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI4wkTWzPoBN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(vol_arr,ret_arr,c=sharpe_arr,cmap='plasma')\n",
        "plt.colorbar(label='Sharpe Ratio')\n",
        "plt.xlabel('Volatility')\n",
        "plt.ylabel('Return')\n",
        "\n",
        "# Add red dot for max SR\n",
        "plt.scatter(max_sr_vol,max_sr_ret,c='red',s=50,edgecolors='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLuwk0cGPoBN"
      },
      "source": [
        "# Mathematical Optimization\n",
        "\n",
        "There are much better ways to find good allocation weights than just guess and check! We can use optimization functions to find the ideal weights mathematically!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mUnuHDyPoBN"
      },
      "source": [
        "### Functionalize Return and SR operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jtnrYsy6PoBO"
      },
      "outputs": [],
      "source": [
        "def get_ret_vol_sr(weights):\n",
        "    \"\"\"\n",
        "    Takes in weights, returns array or return,volatility, sharpe ratio\n",
        "    \"\"\"\n",
        "    weights = np.array(weights)\n",
        "    ret = np.sum(log_ret.mean() * weights) * 252\n",
        "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
        "    sr = ret/vol\n",
        "    return np.array([ret,vol,sr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MsLAcgcqPoBO"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXFxdghgPoBO"
      },
      "source": [
        "To fully understand all the parameters, check out:\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isferYKnPoBO"
      },
      "outputs": [],
      "source": [
        "help(minimize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQA49NjIPoBP"
      },
      "source": [
        "Optimization works as a minimization function, since we actually want to maximize the Sharpe Ratio, we will need to turn it negative so we can minimize the negative sharpe (same as maximizing the postive sharpe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xp9AJbWPPoBQ"
      },
      "outputs": [],
      "source": [
        "def neg_sharpe(weights):\n",
        "    return  get_ret_vol_sr(weights)[2] * -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XtdHs3qbPoBQ"
      },
      "outputs": [],
      "source": [
        "# Contraints\n",
        "def check_sum(weights):\n",
        "    '''\n",
        "    Returns 0 if sum of weights is 1.0\n",
        "    '''\n",
        "    return np.sum(weights) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IhScRALYPoBR"
      },
      "outputs": [],
      "source": [
        "# By convention of minimize function it should be a function that returns zero for conditions\n",
        "cons = ({'type':'eq','fun': check_sum})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bT_IQKz4PoBS"
      },
      "outputs": [],
      "source": [
        "# 0-1 bounds for each weight\n",
        "bounds = ((0, 1), (0, 1), (0, 1), (0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vMXdBsW6PoBS"
      },
      "outputs": [],
      "source": [
        "# Initial Guess (equal distribution)\n",
        "init_guess = [0.25,0.25,0.25,0.25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NAEwJmIdPoBS"
      },
      "outputs": [],
      "source": [
        "# Sequential Least SQuares Programming (SLSQP).\n",
        "opt_results = minimize(neg_sharpe,init_guess,method='SLSQP',bounds=bounds,constraints=cons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iO9ORK_PoBS"
      },
      "outputs": [],
      "source": [
        "opt_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20D7KRquPoBT"
      },
      "outputs": [],
      "source": [
        "opt_results.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8b6mEpuPoBT"
      },
      "outputs": [],
      "source": [
        "get_ret_vol_sr(opt_results.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX8Lz3WgPoBT"
      },
      "source": [
        "# All Optimal Portfolios (Efficient Frontier)\n",
        "\n",
        "The efficient frontier is the set of optimal portfolios that offers the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. Portfolios that lie below the efficient frontier are sub-optimal, because they do not provide enough return for the level of risk. Portfolios that cluster to the right of the efficient frontier are also sub-optimal, because they have a higher level of risk for the defined rate of return.\n",
        "\n",
        "Efficient Frontier http://www.investopedia.com/terms/e/efficientfrontier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "auCvzSniPoBT"
      },
      "outputs": [],
      "source": [
        "# Our returns go from 0 to somewhere along 0.3\n",
        "# Create a linspace number of points to calculate x on\n",
        "frontier_y = np.linspace(0,0.3,100) # Change 100 to a lower number for slower computers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZaNgEeX5PoBT"
      },
      "outputs": [],
      "source": [
        "def minimize_volatility(weights):\n",
        "    return  get_ret_vol_sr(weights)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4l6eg3tRPoBT"
      },
      "outputs": [],
      "source": [
        "frontier_volatility = []\n",
        "\n",
        "for possible_return in frontier_y:\n",
        "    # function for return\n",
        "    cons = ({'type':'eq','fun': check_sum},\n",
        "            {'type':'eq','fun': lambda w: get_ret_vol_sr(w)[0] - possible_return})\n",
        "\n",
        "    result = minimize(minimize_volatility,init_guess,method='SLSQP',bounds=bounds,constraints=cons)\n",
        "\n",
        "    frontier_volatility.append(result['fun'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tNEp8q8PoBU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(vol_arr,ret_arr,c=sharpe_arr,cmap='plasma')\n",
        "plt.colorbar(label='Sharpe Ratio')\n",
        "plt.xlabel('Volatility')\n",
        "plt.ylabel('Return')\n",
        "\n",
        "\n",
        "\n",
        "# Add frontier line\n",
        "plt.plot(frontier_volatility,frontier_y,'g--',linewidth=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9nJ9095PoBU"
      },
      "source": [
        "# Great Job!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}